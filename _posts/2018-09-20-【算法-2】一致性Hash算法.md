---
layout:  post    # 使用的布局（不需要改）
catalog: true   # 是否归档
author: 陈国林 # 作者
tags:         #标签
    - 算法
---

# 一. 概述
`一致性Hash` 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对`K/n`个key重新映射，其中`K`是key的数量，`n`是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有key进行重新映射。

# 二. 引出
我们先看一个问题: 假设有`1000w`个数据项，`100`个存储节点，请设计一种算法合理地将他们存储在这些节点上？

看一看普通Hash算法的原理  
![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-1.png?raw=true)

算法设计得核心  
![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-2.png?raw=true)

普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于1%。之所以分布均匀，主要是依赖Hash算法（实现使用的MD5算法）能够比较随机的分布。

然而，我们看看存在一个问题，由于该算法使用节点数取余的方法，强依赖节点的数目，因此，当节点数发生变化的时候，数据所对应的节点发生剧烈变化，而发生变化的成本就是我们需要在节点数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的，我们观察一下增加节点后，数据项移动的情况 

![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-3.png?raw=true)

结论: `如果有100个数据，当增加一个节点，之前99%的数据都需要重新移动，这显然是不能忍的`

# 三. 登场
上面我们介绍了普通Hash算法的劣势，即当节点数发生变化（增加、移除）后，数据项会被重新`打散`，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。

那么，一个亟待解决的问题就变成了: 当节点数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数数据，保证原来分配到的某个节点，现在仍然应该分配到那个节点，将数据迁移量的降到最低。

一致性Hash算法的原理是这样的  
![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-4.png?raw=true)

从最初的`1000w`个数据项经过一般的哈希算法的模拟来看，这些数据项`打散`后，是可以比较均匀分布的。但是引入一致性哈希算法后，为什么就不均匀呢？数据项本身的哈希值并未发生变化，变化的是判断数据项哈希应该落到哪个节点的算法变了。  
![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-5.png?raw=true)

因此，主要是因为这100个节点Hash后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。

# 四. 虚节点
当我们将节点进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。  
![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/consistency-hash-6.png?raw=true)

通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。


