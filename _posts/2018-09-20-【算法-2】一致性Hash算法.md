---
layout:  post    # 使用的布局（不需要改）
catalog: true   # 是否归档
author: 陈国林 # 作者
tags:         #标签
    - 算法
---

# 一. 概述
一致性哈希是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

# 二. 引出
我们在上文中已经介绍了一致性Hash算法的基本优势，我们看到了该算法主要解决的问题是：当slot数发生变化时，能够尽量少的移动数据。那么，我们思考一下，普通的Hash算法是如何实现？又存在什么问题呢？

引出问题：假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上？

看一看普通Hash算法的原理：![ ](https://upload-images.jianshu.io/upload_images/11046879-56ca97134b11322b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

算法设计得核心

[图片上传中...(image-df8a02-1520690978489-0)] 

普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于1%。之所以分布均匀，主要是依赖Hash算法（实现使用的MD5算法）能够比较随机的分布。

然而，我们看看存在一个问题，由于该算法使用节点数取余的方法，强依赖node的数目，因此，当是node数发生变化的时候，item所对应的node发生剧烈变化，而发生变化的成本就是我们需要在node数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的，我们观察一下增加node后，数据项移动的情况 ![](https://upload-images.jianshu.io/upload_images/11046879-7f62c0f0f62c7e5e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

结论：如果有100个item，当增加一个node，之前99%的数据都需要重新移动
这显然是不能忍的, 没错我们的一致性hash算法闪亮登场

# 三. 登场
我们上节介绍了普通Hash算法的劣势，即当node数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。

那么，一个亟待解决的问题就变成了：当node数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数item，保证原来分配到的某个node，现在仍然应该分配到那个node，将数据迁移量的降到最低。

一致性Hash算法的原理是这样的：![](https://upload-images.jianshu.io/upload_images/11046879-33296ae4615bf8fa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

从最初的1000w个数据项经过一般的哈希算法的模拟来看，这些数据项“打散”后，是可以比较均匀分布的。但是引入一致性哈希算法后，为什么就不均匀呢？数据项本身的哈希值并未发生变化，变化的是判断数据项哈希应该落到哪个节点的算法变了。![](https://upload-images.jianshu.io/upload_images/11046879-b76dbf48f68e3241.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

因此，主要是因为这100个节点Hash后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。

# 四. 虚节点
当我们将node进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。![](https://upload-images.jianshu.io/upload_images/11046879-c0698cb258fc2afe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。
