---
layout:  post  # 使用的布局（不需要改）
catalog: true  # 是否归档
author: 陈国林 # 作者
tags:          #标签
    - 缓存
---

# 一. 缓存原理
1. 缓存定义  
   缓存: 计算机领域非常通用的概念。它介于应用缓存和永久性数据存储源（如硬盘上的文件或者数据库）之间，其作用是降低应用程序直接读写永久性数据存储源的频率，从而提高应用的运行性能。  
   缓存中的数据是数据存储源中数据的拷贝，缓存的物理介质通常是内存。

2. 缓存基本思想
   + 时间局限性原理: 被获取过一次的数据在未来还被多次引用，例如 `一条热门的微博被一个人看了之后，它还会被数以百万、千万级的用户查看`
   + 以空间换时间: 因为原始数据访问太慢，所以我们开辟一块存储空间，用于提供高效数据访问
   + 性能成本权衡: 构建系统时需要在系统性能和开发运行成本直接做取舍，例如 `相同成本的SSD硬盘容量是内存的10~30倍，但是读写延迟确高出50~100倍`
   
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/cache-pyramid.png?raw=true)

3. 缓存优势
   + 提升访问性能: 缓存中存储的一般是需要频繁访问的数据，能够提升整体访问的性能，降低访问延迟
   + 降低网络拥塞: 缓存中存储的数据比DB中的原始数据小很多，降低访问DB的流量，降低网络拥堵
   + 减轻服务负载: 缓存的读写承载能力一般比DB大`10~100`倍以上，减少了原始数据的解析和计算，减轻服务负载
   + 增强扩展性: 可以快速部署上线，也可以随时下线
   
4. 缓存代价
   + 系统复杂度提升
   + 成本增加
   + 多份数据一致性问题（CAP）

5. 一般来说业务全量数据可以放在DB中，例如MySQL、HBASE等。但是DB单实例的性能一般，例如MySQL线上QPS最高`3000~6000`，读写平均耗时在`10~100ms`之间。而缓存的性能正是可以来弥补这种DB的性能不足，例如Memcached QPS可以达到`10~100万`之间，读写平均耗时在`1ms`以内。

# 二. 缓存读写模式
由于缓存组件的存在，容易存在缓存和DB数据不一致，因此好的缓存读写模式非常关键。`不过没有哪一种模式是最好的，需要根据业务场景来做系统设计，往往需要在成本和高性能之间做权衡。`

## ① Cache Aside (旁路缓存)
先看一个错误的缓存更新模式 `更新缓存数据时，先删除缓存，然后再更新DB` 。试想有两个并发操作，一个是更新操作，另一个是查询操作。更新操作删除缓存后，查询操作没有命中缓存，先把DB中老数据读出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老的数据，导致缓存中的数据是脏的。

Cache Aside是最常用的缓存读写模式，我们看一下它的读写过程

1. 读: 如果命中缓存直接返回数据；如果没有命中，则从DB中读取，并写入缓存
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/cache-aside-read.png?raw=true)
2. 写: 先更新DB，再删除缓存
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/cache-aside-update.png?raw=true)

特点: 数据具有更强一致性，确认以DB数据为准，大幅度降低DB和缓存数据不一致概率，业务需要同时维护缓存和DB两个存储组件。

这个模式是标准的缓存读写模式，可以解决两个并发操作，一个是更新操作，另一个是查询操作，导致缓存脏数据问题。  
两个并发操作，一个是更新操作，另一个是查询操作。更新操作更新DB后，如果缓存未删除查询操作直接返回缓存中数据，如果缓存已删除查询操作会先查DB数据，然后再更新缓存，能够保证缓存中的数据和DB保持一致。

但是很多人可能会想`在更新DB数据后，为什么不直接更新缓存，而是删除缓存`？

[Why-does-Facebook-use-delete-to-remove-the-key-value-pair-in-Memcached-instead-of-updating-the-Memcached-during-write-request-to-the-backend](https://www.quora.com/Why-does-Facebook-use-delete-to-remove-the-key-value-pair-in-Memcached-instead-of-updating-the-Memcached-during-write-request-to-the-backend) 这个讨论说到了，如果有2个并发同时更新数据，会存在缓存和DB中的数据不一致的情况。

正常来说为了保证缓存和DB数据一致性，通常有以下几种做法  
1. 任何时候保证只能有一个并发操作（不可能）
2. 分布式高并发场景下使用 `2PC` 或 `Paxos or Raft`协议保证一致性（太复杂）
3. 降低数据不一致的概率，而更新DB数据后删除缓存正是一种降低概率的手段
4. 给缓存设置过期时间，过期时间越短，数据一致性越高。但是过期越短，查数据库就会越频繁

因此，基于以上分析，大部分场景下我们可以使用 Cache Aside 读写模式来保证缓存和DB中的数据一致，同时给缓存设置过期时间

## ② Read/Write Through (读写穿透)
相对于 Cache Aside 模式，Read/Write Throug 模式则使用 `统一存储服务` 封装了缓存和DB，对于业务来说只需要关心业务逻辑，而不再需要关心DB和缓存两个组件。

1. 读: 如果命中直接返回；如果没有命中则先查DB并回写到缓存再返回
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/read-write-throug-1.png?raw=true)
2. 写: 如果数据在缓存中不存在则只更新DB；如果数据在缓存中存在则先更新缓存再更新DB (更新缓存和DB是一个同步操作)
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/read-write-throug-2.png?raw=true)
   
特点: 存储服务封装了所有的数据处理细节，业务应用端代码只需要关注业务逻辑，系统隔离性更好，另外在写操作时如果缓存中没数据则不更新缓存只更新DB，缓存中有数据才更新缓存和DB，内存的效率更高。 
   
## ③ Write Behind Caching (异步缓存写入)
和 Read/Write Throug 模式一样 Write Behind Caching 模式也由统一的存储服务，差别在于数据更新时Read/Write Throug会同步更新缓存和DB，而Write Behind Caching只更新缓存不直接更新DB，采用异步批量方式更新DB。

1. 读: 如果命中直接返回；如果没有命中则先查DB并回写到缓存再返回
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/read-write-throug-1.png?raw=true)
2. 写: 只更新缓存，然后异步更新DB
   ![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/write-behind-caching.png?raw=true)

特点: 数据写的性能非常高，非常适合数据变更非常频繁的业务，可以合并DB写请求的业务。例如一条feed增加1w次点赞，写1w次DB代价是很大的，如果能够合并成1次变成直接加1w性能就会好很多。但是这种模式有个显著的问题就是数据一致性得不到保证，在一些极端的场景下可能会丢数据，例如缓存机器宕机了，数据如果还未保存到DB这个时候就会有数据丢失的风险。`所以非常适合变更频率非常高，数据一致性要求不高的业务，例如微博点赞数，写DB可以异步合并写，性能非常好`

# 三. 缓存分类
1. 按宿主机层次划分
   + 本地缓存: 进程内缓存，读写性能超高，没有网络开销，当进程重启之后数据会丢失
   + 进程间缓存: 同机部署的独立缓存，性能高网络开销小，同机混部存在资源抢夺问题
   + 远程缓存: 跨机器部署的缓存，容量大且易扩展，在高读写压力下带宽容易成为瓶颈
2. 本地缓存: 自己写的Map、LRUCache、Guava Cache等
3. 进程间缓存/远程缓存: Redis、Memcached、Pika等
4. 按存储介质划分
   + 内存型缓存: 数据存储在内存中，读写性能很高，重启会导致数据丢失（如果没有持久化)，例如Memcached、Redis
   + 持久化缓存: 数据存在在SSD等硬盘上，容量很大，数据能够持久化存储，但是读写性能相对较低，例如Pika或者其他基于RocksDB的缓存系统

# 四. 缓存架构设计
1. 读写方式: 是否只整体读写Value；是否部分读写及变更；是否需要内部计算
2. KV size: size过大需要拆分成多个value；size差异过大的业务数据分置在不同缓存池中
3. Key数量: 如果key不大则可以在缓存中存所有的key当DB使用，如果key很多则在缓存中尽可能保留热点数据
4. 读写峰值: 如果读写峰值小于10w QPS直接使用独立缓存池；如果读写峰值大于10w就需要对缓存进行分层，分为本地缓存和远程缓存
5. 命中率: 核心业务需要预留足够容量，保证缓存命中率在99.5%以上
6. 过期策略: 设置较短的时间自动过期；也可以在key上带时间戳，过了指定时间这个key就可以被删除了
7. 平均穿透加载时间: 需要保证缓存穿透后加载时间不会太长
8. 可运维性: 缓存组件集群管理，扩缩容、监控报警，运维工具集成
9. 安全性: 限制来源IP访问只运行内网访问，对于关键指令增加访问权限

