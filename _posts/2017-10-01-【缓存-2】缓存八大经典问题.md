---
layout:  post  # 使用的布局（不需要改）
catalog: true  # 是否归档
author: 陈国林 # 作者
tags:          #标签
    - 缓存
---

# 一. 缓存失效
我们知道缓存的性能是DB的50~100倍，因此我们希望能够借助缓存实现数据快速访问同时达到性能最高。

1. `缓存失效`: 大部分情况下业务数据写缓存都是`key:value`形式，如果某个时间点业务key大量失效，导致请求缓存未命中穿透到DB后DB压力明显上升，系统性能变差最终影响业务请求。
2. `缓存失效原因`: 跟我们设置的key过期时间相关
   + 正常写缓存的时候都会给每个key设置一个过期时间，因为key是慢慢写入的，所以不会出现大量key同时过期
   + 某个特殊的场景，我们会主动/被动的加载一批数据到缓存，这个时候如果设置的过期时间一样就会出现同一批key同时过期问题。当这批key都过期之后，请求穿透到DB，因为DB的性能比缓存差很多，就会导致DB压力大增最终影响业务
3. `缓存失效场景`
   + 火车票: 同一批次火车票在同一个时间点一起加载到缓存，某个时间出现同一批key同时过期问题，业务大量读写请求直接穿透到DB
   + 热门微博: 微博离线系统，分钟/小时级别计算出当前热门的一批微博并加载到缓存，某个时间出现同一批key同时过期问题，业务大量读写请求直接穿透到DB
   + 缓存预热: 系统一次性预加载一批数据，某个时间出现同一批key同时过期问题，业务大量读写请求直接穿透到DB
4. `缓存失效解决方案`: 对每个key不再设置固定的过期时间，而是使用公式 `base+random` 计算出一个过期时间，这样保证每个key的过期时间不同。base表示原来过期时间，random表示随机值  

# 二. 缓存穿透
正常情况下我们访问缓存的策略是: 如果命中缓存直接返回，如果没有命中则从DB中读然后再回写到缓存。

1. `缓存穿透`: 有一批特殊的请求正在查询一个不存在的key，每次请求都无法命中缓存，查询DB后返回一个空数据，这个数据并不会写到缓存，所以导致每次请求都穿透到DB，对DB造成巨大的压力。因为DB的性能只有缓存的1%~5%，所以系统性能就会急剧下降。
2. `缓存穿透原因`: 我们在做系统设计的时候考虑的更多的正常的case而忽略了异常的case，这些异常case会直接穿透到DB
3. `缓存穿透场景`
   + 通过不存在的UID访问不存在的用户信息，导致每次请求都直接穿透到DB
   + 通过不存在的车次ID查询不存在的火车票信息，导致每次请求都直接穿透到DB
4. `缓存穿透解决方案`
   + 方案一: `对不存在的key也写到缓存中`，只不过存储的值是特殊值，这样就不会每次请求都穿透到DB。但是这个方案有个问题，如果不存在的key非常多，会占用很多缓存空间，导致正常key的命中率下降
     + `所以我们可以对这些不存在的key只存一个相对较短的时间(30s)，让这些key尽快过期`
     + `把这些不存在的key存储在另外一个独立缓存中`，业务在查找的时候先查正常缓存，如果命中则直接返回，如果未命中则查独立缓存，如果命中独立缓存直接返回空数据，如果未命中独立缓存则查DB，DB查出来有数据则回写到正常缓存中，DB查出来没有数据则回写到独立缓存中
   + 方案二: `构建一个布隆过滤器`，阻挡这些非法key请求，通过空间换时间非常高效，具体算法可以参考 [布隆过滤器算法](https://chenguolin.github.io/2018/09/20/%E7%AE%97%E6%B3%95-3-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%AE%97%E6%B3%95/)。
     + `通过布隆过滤器预选存储所有正常key`，查缓存之前先查一下布隆过滤器，如果返回不存在说明key肯定不存在直接返回，否则就正常查缓存，但是这就要求key的数量不能太多
     + `通过布隆过滤器存储不存在key`，每次查询到不存在key就加入到布隆过滤器中。查缓存之前先查一下布隆过滤器，如返回不存在说明key可能是正常的就正常查缓存，否则直接返回，但是这种情况是布隆过滤器会慢慢膨胀，需要定期做清零处理

# 三. 缓存击穿
1. `缓存击穿`: 缓存击穿是缓存失效的一个特例，大家使用过微博的应该都知道，微博有一个热门话题的功能，用户对于热门话题的搜索量往往在一些时刻会大大的高于其他话题，这种我们称为系统的"热点"数据，由于系统中对这些热点数据缓存也存在失效时间，在热点的缓存到达失效时间时，此时可能依然会有大量的请求到达系统，没有了缓存层的保护，这些请求同样的会到达DB从而可能引起故障。`缓存击穿是对于特定的热点数据失效，而缓存失效是针对大量的数据同时失效`。
2. `缓存击穿原因`: 热点数据缓存key失效导致
3. `缓存击穿场景`: 热门微博缓存失效，导致大量请求直接穿透到DB，造成DB压力大增，服务出现不可用
4. `缓存击穿解决方案`: 解决此问题的关键在于热点访问，热点数据总是在变化的，或是频率热点，或是流量热点，针对固定的数据进行特殊缓存是不能起到治本作用的
   + 方案一: `采用LRU（Least recently used，最近最少使用）算法`，根据数据的历史访问记录来进行淘汰数据，其核心思想是 `如果数据最近被访问过，那么将来被访问的几率也更高`。最常见的实现是使用一个链表保存缓存数据，这个链表即是我们的缓存结构。首先将新数据放入链表的头部，链表中有数据被再次访问那么就插入到链表的头部，最后当链表数据放满时将底部的数据淘汰，也就是不常访问的数据。这个方案有个问题，偶然的数据影响会造成命中率较低，比如某个数据即将被淘汰，但由于一次的请求又放入了头部，此后再无该数据的请求，那么该数据的继续存在其实是不合理的。
   + 方案二: `采用多级LRU的数据结构`，相比LRU算法LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，LRU-K会淘汰第K次访问时间距当前时间最大的数据。数据第一次被访问会先加入到访问历史队列，当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除并移到缓存队列中，数据被再次访问的时候更新缓存队列，如果数据在访问历史队列里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰。实际应用中LRU-2是综合各种因素后最优的选择，利用更多的内存空间来用来构建缓存，较好的降低了数据的污染率提高了缓存的命中率。

# 四. 缓存雪崩
1. `缓存雪崩`: 缓存雪崩是一个非常严重的问题，指的是部分缓存节点不可用，导致整个缓存服务系统不可用，分为以下2种情况
    + 缓存不支持rehash导致的系统雪崩不可用: 较多的缓存节点不可用导致大量请求穿透到DB，DB过载不可用，最终导致整个服务系统不可用。
    + 缓存支持rehash导致的缓存雪崩不可用: 雪崩跟洪峰流量有关系，部分缓存节点过载宕机，请求rehash流量扩散到其它缓存节点，导致整个缓存系统不可用。
2. `缓存雪崩场景`
    + 缓存不支持rehash导致的系统雪崩不可用: 当较多缓存节点不可用的时候，大量的缓存请求会失败，进一步穿透到DB，由于DB可承载的访问量只有缓存的`1~2%`，请求量过大时引发DB过载，最终导致服务不可用。
    + 缓存支持rehash导致的缓存雪崩不可用: 缓存分布设计的时候大部分选择的是`一致性hash`算法来保证数据均匀分布，在洪峰流量来临的时候，如果大流量的key集中在`1~2`个节点上，大流量的key所在的缓存节点过载宕机后节点下线，节点数据迁移，缓存请求会rehash到其它节点上，进一步导致其它缓存节点也过载宕机，恶性循环最终导致缓存服务不可用。（`正常情况下使用 一致性hash+rehash 可以很好运行`）
3. `缓存雪崩解决方案`
    + 方案一: 增加DB读写开关，当DB慢请求超过一定的阈值的时候，关闭`读`DB的开关，请求立即返回`failfast`。当DB恢复后，再打开`读`开关
    + 方案二: 缓存增加多副本，任何缓存未命中就改为读其他缓存副本，而且多个缓存副本尽量部署在多个机架上，确保缓存系统高可用
    + 方案三: 对缓存系统进行实时监控，当缓存请求的慢速比超过一定阈值的时候，及时发现问题并恢复，同时增加自动故障转移策略 （通过各种开关设置）

# 五. 数据不一致
1. `数据不一致`: 数据同时存在缓存和DB，所以可能存在缓存和DB数据不一致。同时缓存会有多个副本，也可能存在多个副本之间数据不一致的情况。
2. `数据不一致场景`
    + 更新DB后，缓存机器出现异常，更新/淘汰缓存数据请求失败，导致缓存和DB数据不一致
    + 缓存采用一致性hash+rehash机制，节点出现异常，多次上下线后也会导致数据不一致
3. `数据不一致解决方案`
    + 方案一: 缓存更新/淘汰失败后可以进行多次重试，重试失败后可以把这些key写入消息队列，待缓存节点恢复后，通过处理机消费队列延迟删除这些key
    + 方案二: 调短缓存过期时间，让缓存自动过期，通过重新加载来保证最终缓存和DB数据一致
    + 方案三: 拒绝rehash策略，采用缓存分层策略，尽量避免脏数据产生

# 六. 数据并发竞争
1. `数据并发竞争`: 互联网系统数据并发较大，容易出现数据并发的现象。在高并发的场景下，如果缓存未命中，大量的并发就会请求到DB，导致DB压力大增。
2. `数据并发竞争原因`: 大量并发请求相同的key，但是key不在缓存中，没有任何并发限制，并发查询DB后，导致DB压力大增
3. `数据并发竞争场景`
    + 车次信息: 春节抢票期间，某个车次缓存信息过期，但仍有大量的用户在同时查询该车次信息
    + 热门微博: 某条微博缓存数据过期，但仍有大量的用户同时在转发、评论和访问该微博
4. `数据并发竞争解决方案`
    + 方案一: `使用全局锁` 当请求缓存不存在的时候，设置一个全局锁（分布式锁），只有抢到锁的进程/线程才能够操作DB，其它未抢到锁的进程/线程就等待，等待加锁线程回写进缓存并释放锁之后就可以从缓存中访问。
    + 方案二: `缓存多备份` 对缓存数据设置多个副本/备份，访问未命中就请求其它缓存副本

# 七. Hot key
1. `Hot key`: 对于大数据互联网的业务来说数据是分`冷、热`的，最近最新的数据被访问的频率高很多，比较久远的数据被访问频率会小很多。当有突发事件发生的时候，大量用户同时访问这个热数据，导致这个热key所在的缓存节点服务过载，导致服务请求变慢或出现异常。
2. `Hot key原因`: 突发热门事件发生，超大量的请求访问这个热key，这些流量会集中请求到一个缓存节点，导致缓存节点达到CPU、物理网卡、带宽上限，从而导致服务异常。
3. `Hot key场景`
    + 明星结婚、离婚等突发事件
    + 奥运、春节等重大活动
    + 秒杀、双11等线上促销活动
4. `Hot key解决方案`
    + 方案一: 热key分散存储，分别命名为`hotkey_1`、`hotkey_2` ...，这些热key分散存储在不同缓存节点上，客户端在请求缓存的时候随机请求某个后缀的热key，达到分散请求的目的
    + 方案二: SLA监控实时发现，通过快速扩容
    + 方案三: 业务增加本地缓存来减少对缓存服务的请求

# 八. Big key
1. `Big key`: 部分key的value过大，导致缓存读写加载容易超时
   + 大key存mc，对应的slab较少，导致频繁的被剔除，DB就会反复加载
   + key的value过大，如果key被频繁访问，那么缓存组件的带宽、网卡就会被打满
   + key的存储字段过多，每个字段变更都需要对缓存数据进行变更，读写相互影响
   + 大key如果被缓存淘汰，DB需要加载大量的数据，加载时间长
2. `Big key场景`
   + 用户
3. `Big key解决方案`
   + 方案一:
   + 方案二: 

