---
layout:  post  # 使用的布局（不需要改）
catalog: true  # 是否归档
author: 陈国林 # 作者
tags:          #标签
    - K8s
---

# 一. 背景
每个应用程序都会打印日志，通过日志可以帮助我们了解应用程序内部发生了什么，日志也被用于调试问题和监控应用程序，日志使得应用程序运行的动作变得透明。

传统的应用程序日志有以下几个特点

1. 传统应用程序是直接部署在一个或多个物理机(虚拟机)上，业务按单体或微服务方式进行部署。
2. 应用程序按照类型把日志输出到物理机指定目录文件，并进行滚动切割。
3. 业务日志格式随意，没有统一方式
4. 业务通过登录部署服务器，进行日志查看和问题排查
5. 业务运维使用工具进行日志压缩、备份和清理

由上面几个点我们知道，传统日志架构基本是为开发或运维提供排查问题的信息，是面向人去设计的，人脑天生适合处理非结构化的数据，因此日志信息非常随意。

但是随着微服务、容器化技术的发展促使我们的应用部署架构发生了变化，业务容器化后会面临以下几个问题
1. 业务Pod部署所在的宿主机不定，登录服务器查看日志方式不太可行
2. 业务Pod有生命周期，当Pod销毁的时候日志也就会丢失 
3. 传统的使用日志进行统计、报警、分析等行为均会受限
4. 由于容器的隔离性，日志文件通常是对外不可访问的
5. 容器存储空间有限，长时间的写入日志文件，也可能造成容器存储空间打满，导致容器挂掉
6. 业务容器化后日志架构面临诸多挑战 

由上可知，传统的日志架构已经不再适用，在业务全面容器化的时代，我们亟需找到一种新的日志架构来适应容器化环境。

我们期望日志的输出具有统一的结构化的格式，服务将日志输出到标准输出，不需要关心日志如何落地。运行环境截获日志并由统一的日志收集Agent将日志过滤，处理，采集，通过日志传输组件（比如kafka）分发给不同处理程序。

# 二. Kubernetes日志架构
大部分现代应用都有各种日志机制，因此，大部分容器引擎也被设计支持各种日志。对于容器化的应用来说，最简单也最推荐的日志采集方法是将日志写到标准输出和标准错误输出。

在k8s中，Pod所在的机器并不固定，无法直接查看日志，同时日志会随着Pod的重启而丢失。为了适应这种情况，需要将日志收集到统一的日志中心，以便查询和分析。根据日志的输出形式可以将日志划分为 `标准输出日志`、`文件输出日志`

## ① 标准输出日志
容器化应用通过stdout和stderr输出日志，然后由容器引擎处理，例如Docker默认使用JSON file做为log-driver，通过接管stdout和stderr把日志写到JSON文件中。

Docker在启动的过程中，会接管容器的标准输出，然后交给log-driver处理，这些日志会写到文件`/var/lib/docker/container/`路径下，可以在每个K8s worker节点上启动采集Agent，收集这些日志文件。在k8s中，一般通过DeamonSet保证每个worker节点都启动一个采集Agent。

![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/k8s-logging-with-node-agent.png?raw=true)

## ② 文件输出日志
对于那些没有办法输出到stdout和stderr的日志，还是继续输出到文件，只不过日志文件由于是在容器内，由于隔离性存在容器内文件并不能被直接访问，因此我们会使用
sidecar容器，读取文件内容并输出到标准输出，这样就可以通过标准输出的流程收集这些日志。

![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/k8s-logging-with-streaming-sidecar.png?raw=true)

# 三. 采集方案
## ① 业务需求
业务对日志的需求归纳总结起来就是以下几点

1. 日志查看 (grep命令，需要有全文检索功能)
2. 日志报警 (根据ERROR日志告警)
3. 日志统计 (根据日志统计各种信息)
4. 命令行查看日志
5. 离线计算和分析

## ② 采集核心诉求
针对业务的需求，日志采集这边的核心诉求归纳总结起来主要是以下几点

1. 日志不丢
2. 日志不会重复采集
3. 时效性强
4. 采集流程可定制
5. 具有日志所属K8s相关meta信息，唯一标识
6. 支持监控告警

## ③ 标准输出日志采集
根据Kubernetes日志架构方案，以及业务需求和采集的核心诉求，`标准输出日志采集`方案为 `Fluentd + Kafka + ELK`，通过Fluentd进行采集，数据写入Kafka不同topic，通过Logstash消费写入ES，最终通过Kibana进行展示查看。

1. 使用Fluentd做为每个K8s worker节点的采集Agent
    + 社区活跃: CNCF官方项目 ，Kubernetes官方推荐采集器
    + 扩展性强: 源码开源，配置简单，通过插件化形式来管理数据处理流程，650+开源插件
    + 性能好: C和Ruby编写，极简模式下单进程采集能力15MB/s，支持多进程，性能可线性扩展
2. 使用Kafka做为消息队列，时效性强，当ES写入有瓶颈时，可以用来缓存数据
3. 使用ELK做为数据消费、存储、展示
    + Elasticsearch: 基于Lucene的全文检索引擎，存储容量大，保存周期长
    + 使用Kibana支持高级搜索功能，日志查看很方便
    + 还能基于Kibana做离线统计、分析

![](https://github.com/chenguolin/chenguolin.github.io/blob/master/data/image/k8s-logging-stdout.png?raw=true)

## ④ 文件输出日志采集
根据Kubernetes日志架构方案，以及业务需求和采集的核心诉求，`文件输出日志采集`方案为 `sidecar容器 + Fluentd + Kafka + ELK`，通过sidecar容器导出到标准输出后，使用Fluentd进行采集，数据写入Kafka不同topic，通过Logstash消费写入ES，最终通过Kibana进行展示查看。

# 四. 组件介绍
## ① Fluentd


